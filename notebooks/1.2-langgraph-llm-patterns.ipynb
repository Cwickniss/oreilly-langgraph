{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining Pattern for Quiz Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by this [article by Anthropic](https://www.anthropic.com/research/building-effective-agents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "llm_structured = ChatOllama(model=\"llama3.2\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a reviewer that scores the quality of quizzes based on input content.\n",
      "    Consider SOLELY this input below as the source: \n",
      " '''Persistence in LangGraph means keeping state information of the graph throughout its execution..'''\n",
      "    Now, analyse this quiz created based on the input source:\n",
      " '''1. What is life?'''. \n",
      "    Review this quiz and ONLY return:\n",
      "    - 'APPROVED' if the quiz is good enough, relevant and it covers well all the important contents of the original material. \n",
      "    - 'TO-REVIEW' if the quiz is not relevant to the original material showed above, or not comprehensive enough.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TO-REVIEW'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ReviewOutput(BaseModel):\n",
    "    quiz_score: str = Field(description=\"'APPROVED' or 'TO-REVIEW'\")\n",
    "\n",
    "llm_reviewer_structured = llm.with_structured_output(ReviewOutput)\n",
    "\n",
    "input_source = \"Persistence in LangGraph means keeping state information of the graph throughout its execution.\"\n",
    "initial_quiz = \"1. What is life?\"\n",
    "\n",
    "review_prompt = f\"\"\"You are a reviewer that scores the quality of quizzes based on input content.\n",
    "    Consider SOLELY this input below as the source: \\n '''{input_source}.'''\n",
    "    Now, analyse this quiz created based on the input source:\\n '''{initial_quiz}'''. \n",
    "    Review this quiz and ONLY return:\n",
    "    - 'APPROVED' if the quiz is good enough, relevant and it covers well all the important contents of the original material. \n",
    "    - 'TO-REVIEW' if the quiz is not relevant to the original material showed above, or not comprehensive enough.\n",
    "    \"\"\"\n",
    "    \n",
    "print(review_prompt)\n",
    "output = llm_reviewer_structured.invoke(review_prompt)\n",
    "output.quiz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class QuizState(TypedDict):\n",
    "    input_source: str\n",
    "    n_questions: str\n",
    "    quiz: str\n",
    "    quiz_quality_score: str\n",
    "    improved_quiz: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def create_quiz(state: QuizState) -> QuizState:\n",
    "    n_questions = state[\"n_questions\"]\n",
    "    input_source = state[\"input_source\"]\n",
    "    quiz = llm.invoke(f\"Create a markdown styled quiz with {n_questions} given this content:\\n {input_source}\")\n",
    "    return {\"quiz\": quiz.content}\n",
    "\n",
    "def review_quiz(state: QuizState) -> QuizState:\n",
    "    input_source = state[\"input_source\"]\n",
    "    initial_quiz = state[\"quiz\"]\n",
    "    review_prompt = f\"\"\"You are a reviewer that scores the quality of quizzes based on input content.\n",
    "    Consider SOLELY this input below as the source: \\n '''{input_source}.'''\n",
    "    Now, analyse this quiz created based on the input source:\\n '''{initial_quiz}'''. \n",
    "    Review this quiz and ONLY return:\n",
    "    - 'APPROVED' if the quiz is good enough, relevant, has the right number of questions given the input and it\n",
    "    covers well all the important contents of the original material. \n",
    "    - 'TO-REVIEW' if the quiz is not relevant to the original material showed above, or not comprehensive enough.\n",
    "    \"\"\"\n",
    "    \n",
    "    quiz_quality_score_output = llm_reviewer_structured.invoke(review_prompt)\n",
    "    quiz_quality_score = quiz_quality_score_output.quiz_score\n",
    "    \n",
    "    return {\"quiz_quality_score\": quiz_quality_score}\n",
    "\n",
    "def route_quiz_feedback(state: QuizState) -> QuizState:\n",
    "    if state[\"quiz_quality_score\"]==\"APPROVED\":\n",
    "        return \"approved\"\n",
    "    elif state[\"quiz_quality_score\"]==\"TO-REVIEW\":\n",
    "        return \"improve\"\n",
    "    \n",
    "\n",
    "def write_improved_quiz(state: QuizState) -> QuizState:\n",
    "    \n",
    "    input_source = state[\"input_source\"]\n",
    "    initial_quiz = state[\"initial_quiz\"]\n",
    "    \n",
    "    prompt_improve_quiz = f\"\"\"This input was given as the ONLY source: \\n\\n '''{input_source}'''.\n",
    "    This is the first version of a quiz based only on this source: '''{initial_quiz}'''.\n",
    "    Write an improved version of this quiz by:\n",
    "    \n",
    "    1. Consider 3 points of improvement\n",
    "    2. Write the improved version of the quiz integrating the feedback\n",
    "    3. OUTPUT ONLY THE IMPROVED QUIZ AS A NUMBERED LIST.\"\"\"\n",
    "    \n",
    "    improved_quiz = llm.invoke(prompt_improve_quiz)\n",
    "    \n",
    "    return {\"improved_quiz\": improved_quiz.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(QuizState)\n",
    "\n",
    "workflow.add_node(\"create_quiz\", create_quiz)\n",
    "workflow.add_node(\"review_quiz\", review_quiz)\n",
    "workflow.add_node(\"improve_quiz\", write_improved_quiz)\n",
    "\n",
    "workflow.add_edge(START, \"create_quiz\")\n",
    "workflow.add_edge(\"create_quiz\", \"review_quiz\")\n",
    "workflow.add_conditional_edges(\"review_quiz\", route_quiz_feedback, {\"approved\": END, \"improve\": \"improve_quiz\"})\n",
    "workflow.add_edge(\"improve_quiz\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, Image\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_source': '\\n1. Persistence in LangGraph means keeping state information of the graph throughout its execution\\n2. In LangGraph there are 2 fundamental questions to ask: 1. Which variables to track across the graph\\'s execution 2. Which intermediate artifacts are useful for debugging?\\n3. Sub-graphs in langgraph are graphs used as nodes in other graphs (need to share at least 1 key in the state schemas in order to communicate between sub graph and parent graph\\n4. Command in Langgraph is a node that works to update state and route to other nodes\\n5. Arguments for why a framework like langgraph can be useful:\\n    * Implementing foundational agentic patterns does not require a framework like LangGraph.\\n    * LangGraph aims to minimize overhead of implementing these patterns.\\n    * LangGraph provides supporting infrastructure underneath any workflow/agent.\\n\\n    Additionally, here is a breakdown of the specific features mentioned:\\n\\n    * Persistence:\\n    + Memory Area\\n    + Fullscreen Window\\n    + Scrolling\\n    + Timer\\n    + Aa (assuming \"Aa\" refers to some sort of annotation or feedback mechanism)\\n    + Recording\\n    * Human-In-The-Loop:\\n    + Allows for human intervention and oversight in the workflow/agent\\n    * Streaming:\\n    + Enables real-time processing of LLM calls or steps in a workflow/agent\\n',\n",
       " 'n_questions': 5,\n",
       " 'quiz': \"**LangGraph Fundamentals Quiz**\\n=====================================\\n\\nTest your knowledge about LangGraph, a framework for implementing agentic patterns.\\n\\n### Question 1: What does persistence in LangGraph mean?\\n\\nWhat does persistence in LangGraph refer to?\\n| Answer | Description |\\n| --- | --- |\\n| A) Memory Management | Incorrect |\\n| B) Keeping state information of the graph throughout its execution | Correct |\\n| C) Human Intervention | Incorrect |\\n\\n### Question 2: Which fundamental questions should you ask when designing a LangGraph?\\n\\nWhich fundamental questions should you ask when designing a LangGraph?\\n| Answer | Description |\\n| --- | --- |\\n| A) What are the required variables to track across the graph's execution? | Correct |\\n| B) How many intermediate artifacts are useful for debugging? | Correct |\\n| C) Can I use arbitrary nodes in my graph? | Incorrect |\\n\\n### Question 3: What type of nodes can be used as sub-graphs in LangGraph?\\n\\nWhat type of nodes can be used as sub-graphs in LangGraph?\\n| Answer | Description |\\n| --- | --- |\\n| A) Nodes that share a common key in the state schemas with the parent graph | Correct |\\n| B) Any type of node | Incorrect |\\n\\n### Question 4: What is the primary function of a Command node in LangGraph?\\n\\nWhat is the primary function of a Command node in LangGraph?\\n| Answer | Description |\\n| --- | --- |\\n| A) To update state and route to other nodes | Correct |\\n| B) To store data in memory | Incorrect |\\n\\n### Question 5: Why can a framework like LangGraph be useful for implementing agentic patterns?\\n\\nWhy can a framework like LangGraph be useful for implementing agentic patterns?\\n| Answer | Description |\\n| --- | --- |\\n| A) It reduces the complexity of implementing agentic patterns | Correct |\\n| B) It eliminates the need for a custom framework | Incorrect |\\n| C) It provides supporting infrastructure underneath any workflow/agent | Correct |\\n\\n**Additional Features**\\n\\n### Persistence\\n\\nWhich features are included in persistence?\\n| Answer | Description |\\n| --- | --- |\\n| A) Memory Area | Correct |\\n| B) Fullscreen Window | Correct |\\n| C) Scrolling | Correct |\\n| D) Timer | Correct |\\n| E) Aa (annotation or feedback mechanism) | Correct |\\n| F) Recording | Correct |\\n\\n### Human-In-The-Loop\\n\\nWhat type of human intervention is supported by LangGraph?\\n| Answer | Description |\\n| --- | --- |\\n| A) Allows for human intervention and oversight in the workflow/agent | Correct |\\n| B) Requires human intervention to execute tasks | Incorrect |\\n\\n### Streaming\\n\\nWhich feature enables real-time processing of LLM calls or steps in a workflow/agent?\\n| Answer | Description |\\n| --- | --- |\\n| A) Enables streaming | Correct |\\n| B) Disables streaming | Incorrect |\\n\\nLet me know if you need any further assistance!\",\n",
       " 'quiz_quality_score': 'APPROVED'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_source_raw = \"\"\"\n",
    "1. Persistence in LangGraph means keeping state information of the graph throughout its execution\n",
    "2. In LangGraph there are 2 fundamental questions to ask: 1. Which variables to track across the graph's execution 2. Which intermediate artifacts are useful for debugging?\n",
    "3. Sub-graphs in langgraph are graphs used as nodes in other graphs (need to share at least 1 key in the state schemas in order to communicate between sub graph and parent graph\n",
    "4. Command in Langgraph is a node that works to update state and route to other nodes\n",
    "5. Arguments for why a framework like langgraph can be useful:\n",
    "    * Implementing foundational agentic patterns does not require a framework like LangGraph.\n",
    "    * LangGraph aims to minimize overhead of implementing these patterns.\n",
    "    * LangGraph provides supporting infrastructure underneath any workflow/agent.\n",
    "\n",
    "    Additionally, here is a breakdown of the specific features mentioned:\n",
    "\n",
    "    * Persistence:\n",
    "    + Memory Area\n",
    "    + Fullscreen Window\n",
    "    + Scrolling\n",
    "    + Timer\n",
    "    + Aa (assuming \"Aa\" refers to some sort of annotation or feedback mechanism)\n",
    "    + Recording\n",
    "    * Human-In-The-Loop:\n",
    "    + Allows for human intervention and oversight in the workflow/agent\n",
    "    * Streaming:\n",
    "    + Enables real-time processing of LLM calls or steps in a workflow/agent\n",
    "\"\"\"\n",
    "\n",
    "output = graph.invoke({\"input_source\": input_source_raw,\n",
    "                       \"n_questions\": 5})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**LangGraph Fundamentals Quiz**\n",
       "=====================================\n",
       "\n",
       "Test your knowledge about LangGraph, a framework for implementing agentic patterns.\n",
       "\n",
       "### Question 1: What does persistence in LangGraph mean?\n",
       "\n",
       "What does persistence in LangGraph refer to?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) Memory Management | Incorrect |\n",
       "| B) Keeping state information of the graph throughout its execution | Correct |\n",
       "| C) Human Intervention | Incorrect |\n",
       "\n",
       "### Question 2: Which fundamental questions should you ask when designing a LangGraph?\n",
       "\n",
       "Which fundamental questions should you ask when designing a LangGraph?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) What are the required variables to track across the graph's execution? | Correct |\n",
       "| B) How many intermediate artifacts are useful for debugging? | Correct |\n",
       "| C) Can I use arbitrary nodes in my graph? | Incorrect |\n",
       "\n",
       "### Question 3: What type of nodes can be used as sub-graphs in LangGraph?\n",
       "\n",
       "What type of nodes can be used as sub-graphs in LangGraph?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) Nodes that share a common key in the state schemas with the parent graph | Correct |\n",
       "| B) Any type of node | Incorrect |\n",
       "\n",
       "### Question 4: What is the primary function of a Command node in LangGraph?\n",
       "\n",
       "What is the primary function of a Command node in LangGraph?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) To update state and route to other nodes | Correct |\n",
       "| B) To store data in memory | Incorrect |\n",
       "\n",
       "### Question 5: Why can a framework like LangGraph be useful for implementing agentic patterns?\n",
       "\n",
       "Why can a framework like LangGraph be useful for implementing agentic patterns?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) It reduces the complexity of implementing agentic patterns | Correct |\n",
       "| B) It eliminates the need for a custom framework | Incorrect |\n",
       "| C) It provides supporting infrastructure underneath any workflow/agent | Correct |\n",
       "\n",
       "**Additional Features**\n",
       "\n",
       "### Persistence\n",
       "\n",
       "Which features are included in persistence?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) Memory Area | Correct |\n",
       "| B) Fullscreen Window | Correct |\n",
       "| C) Scrolling | Correct |\n",
       "| D) Timer | Correct |\n",
       "| E) Aa (annotation or feedback mechanism) | Correct |\n",
       "| F) Recording | Correct |\n",
       "\n",
       "### Human-In-The-Loop\n",
       "\n",
       "What type of human intervention is supported by LangGraph?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) Allows for human intervention and oversight in the workflow/agent | Correct |\n",
       "| B) Requires human intervention to execute tasks | Incorrect |\n",
       "\n",
       "### Streaming\n",
       "\n",
       "Which feature enables real-time processing of LLM calls or steps in a workflow/agent?\n",
       "| Answer | Description |\n",
       "| --- | --- |\n",
       "| A) Enables streaming | Correct |\n",
       "| B) Disables streaming | Incorrect |\n",
       "\n",
       "Let me know if you need any further assistance!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(output[\"quiz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Pattern with LangGraph\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Image\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainationState(TypedDict):\n",
    "    question: str\n",
    "    analogy: str\n",
    "    examples: str\n",
    "    plain_english: str\n",
    "    technical_definition: str\n",
    "    full_explanation: str\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "def generate_analogy(state: ExplainationState)->ExplainationState:\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    analogy_prompt = f\"\"\"\n",
    "    Given this question by the user:\n",
    "    {question}\n",
    "    Explain it by providing an analogy to help.\n",
    "    \"\"\"\n",
    "    analogy_output = llm.invoke(analogy_prompt)\n",
    "    return {\"analogy\":  analogy_output.content}\n",
    "\n",
    "def generate_example(state: ExplainationState)->ExplainationState:\n",
    "    question = state[\"question\"]\n",
    "    example_prompt = f\"\"\"Given this question by the user: \n",
    "    {question}\n",
    "    Provide 3 examples to help clarify it or demonstrate it in context.\n",
    "    Your OUTPUT SHOULD ONLY BE the examples as a bullet point list.\"\"\"\n",
    "    \n",
    "    examples_output = llm.invoke(example_prompt)\n",
    "    \n",
    "    return {\"examples\": examples_output.content}\n",
    "\n",
    "def explain_plain_english(state: ExplainationState)->ExplainationState:\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    plain_english_prompt = f\"\"\"\n",
    "    Given this question by the user:\n",
    "    {question}\n",
    "    Explain it in simple plain english terms in less than 2 paragraphs.\n",
    "    Output plain english explanation:\n",
    "    \"\"\"\n",
    "    output_plain_english = llm.invoke(plain_english_prompt)\n",
    "\n",
    "    return {\"plain_english\":output_plain_english.content}\n",
    "\n",
    "def explain_technical_definition(state: ExplainationState)->ExplainationState:\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    technical_definition_prompt = f\"\"\"\n",
    "    Given this question by the user:\n",
    "    {question}\n",
    "    Explain it in technical terms not using more than 2 paragraphs. Make sure to be rigid and\n",
    "    give the official technical definition required that answers the question.\n",
    "    Output technical definition:\n",
    "    \"\"\"\n",
    "    technical_definition_output = llm.invoke(technical_definition_prompt)\n",
    "    return {\"technical_definition\": technical_definition_output.content}\n",
    "\n",
    "def generate_final_explanation(state: ExplainationState)->ExplainationState:\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    analogy = state[\"analogy\"]\n",
    "    examples = state[\"examples\"]\n",
    "    plain_english = state[\"plain_english\"]\n",
    "    technical_definition = state[\"technical_definition\"]\n",
    "    \n",
    "    full_explanation = f\"\"\"\n",
    "    # Final answer\n",
    "    \n",
    "    ## Analogy\n",
    "    \n",
    "    {analogy}\n",
    "    \n",
    "    ## Examples\n",
    "    \n",
    "    {examples}\n",
    "    \n",
    "    ## Plain English\n",
    "    \n",
    "    {plain_english}\n",
    "    \n",
    "    ## Technical Definition\n",
    "    \n",
    "    {technical_definition}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return {\"full_explanation\": full_explanation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(ExplainationState)\n",
    "\n",
    "workflow.add_node(\"generate_analogy\",generate_analogy)\n",
    "workflow.add_node(\"generate_example\",generate_example)\n",
    "workflow.add_node(\"explain_plain_english\",explain_plain_english)\n",
    "workflow.add_node(\"explain_technical_definition\",explain_technical_definition)\n",
    "workflow.add_node(\"generate_final_explanation\",generate_final_explanation)\n",
    "\n",
    "workflow.add_edge(START, \"generate_analogy\")\n",
    "workflow.add_edge(START, \"generate_example\")\n",
    "workflow.add_edge(START, \"explain_plain_english\")\n",
    "workflow.add_edge(START,\"explain_technical_definition\")\n",
    "\n",
    "workflow.add_edge(\"generate_analogy\",\"generate_final_explanation\")\n",
    "workflow.add_edge(\"generate_example\",\"generate_final_explanation\")\n",
    "workflow.add_edge(\"explain_plain_english\",\"generate_final_explanation\")\n",
    "workflow.add_edge(\"explain_technical_definition\",\"generate_final_explanation\")\n",
    "workflow.add_edge(\"generate_final_explanation\",END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "graph.invoke({\"question\": \"Explain the concept of self-attention in transformers (context is large language models).\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing\n",
    "\n",
    "Let's look at a simple example of routing between LLMs. We'll create a workflow that:\n",
    "\n",
    "1. Takes a user question\n",
    "2. Routes it to one of three specialized agents:\n",
    "   - Code explanation agent\n",
    "   - Math problem solver\n",
    "   - General knowledge agent\n",
    "3. Gets the specialized response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define our state\n",
    "class RoutingState(TypedDict):\n",
    "    question: str  # Input question\n",
    "    category: str | None # Routing classification\n",
    "    answer: str | None  # Final answer\n",
    "\n",
    "class QuestionType(BaseModel):\n",
    "    category: str = Field(description=\"The category classification of the question: CODE or MATH or GENERAL\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_structured_output = llm.with_structured_output(QuestionType)\n",
    "\n",
    "# Router that classifies the question\n",
    "def route_question(state: RoutingState):\n",
    "    question = state[\"question\"]\n",
    "    response = llm_with_structured_output.invoke(\n",
    "        f\"\"\"Classify this question into exactly ONE category:\n",
    "        - CODE if about programming/coding\n",
    "        - MATH if about mathematical calculations\n",
    "        - GENERAL for general knowledge\n",
    "        Question: {question}\n",
    "        Category:\"\"\"\n",
    "    )\n",
    "    print(response)\n",
    "    return {\"category\": response.category}\n",
    "\n",
    "# Specialized agents\n",
    "def code_expert(state: RoutingState):\n",
    "    print(\"Using code expert!\")\n",
    "    return {\"answer\": llm.invoke(f\"As a coding expert, answer: {state['question']}\")}\n",
    "\n",
    "def math_expert(state: RoutingState):\n",
    "    print(\"Using math expert\")\n",
    "    return {\"answer\": llm.invoke(f\"As a math expert, solve: {state['question']}\")}\n",
    "\n",
    "def general_expert(state: RoutingState):\n",
    "    print(\"Using general expert\")\n",
    "    return {\"answer\": llm.invoke(f\"Answer this general question: {state['question']}\")}\n",
    "\n",
    "# Define routing logic\n",
    "def router(state: RoutingState):\n",
    "    if state[\"category\"] == \"CODE\":\n",
    "        return \"code_expert\"\n",
    "    elif state[\"category\"] == \"MATH\":\n",
    "        return \"math_expert\"\n",
    "    else:\n",
    "        return \"general_expert\"\n",
    "\n",
    "# Create and configure workflow\n",
    "workflow = StateGraph(RoutingState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"route\", route_question)\n",
    "workflow.add_node(\"code_expert\", code_expert)\n",
    "workflow.add_node(\"math_expert\", math_expert) \n",
    "workflow.add_node(\"general_expert\", general_expert)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"route\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"route\",\n",
    "    router,\n",
    "    {\n",
    "        \"code_expert\": \"code_expert\",\n",
    "        \"math_expert\": \"math_expert\",\n",
    "        \"general_expert\": \"general_expert\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"code_expert\", END)\n",
    "workflow.add_edge(\"math_expert\", END)\n",
    "workflow.add_edge(\"general_expert\", END)\n",
    "\n",
    "# Compile and run\n",
    "graph = workflow.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category='CODE'\n",
      "Using code expert!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the time complexity of quicksort?',\n",
       " 'category': 'CODE',\n",
       " 'answer': AIMessage(content='The time complexity of the quicksort algorithm can vary depending on the circumstances:\\n\\n1. **Average Case:** The average time complexity of quicksort is \\\\(O(n \\\\log n)\\\\), where \\\\(n\\\\) is the number of elements in the array. This is because the partitioning process divides the array into two parts, and the recursion depth is approximately \\\\(\\\\log n\\\\), with each level of recursion requiring \\\\(O(n)\\\\) work to partition the array.\\n\\n2. **Best Case:** The best-case time complexity is also \\\\(O(n \\\\log n)\\\\). This occurs when the pivot selection results in equally balanced partitions at each step, leading to a perfectly balanced recursive tree.\\n\\n3. **Worst Case:** The worst-case time complexity is \\\\(O(n^2)\\\\). This occurs when the pivot selection results in highly unbalanced partitions, such as when the smallest or largest element is consistently chosen as the pivot. An example of this situation is when the array is already sorted (or reverse sorted) and the first or last element is chosen as the pivot.\\n\\nTo mitigate the worst-case scenario, techniques such as using a random pivot or the \"median-of-three\" method for pivot selection are often employed, which help ensure that quicksort operates closer to its average-case complexity in practice.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 260, 'prompt_tokens': 23, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-675a3b9d-a5aa-40b0-8191-05f74f6fbe68-0', usage_metadata={'input_tokens': 23, 'output_tokens': 260, 'total_tokens': 283, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\n",
    "     \"question\": \"What is the time complexity of quicksort?\",   # Routes to code expert\n",
    "     \"category\": None,\n",
    "     \"answer\": None\n",
    " })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langgraph",
   "language": "python",
   "name": "oreilly-langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
