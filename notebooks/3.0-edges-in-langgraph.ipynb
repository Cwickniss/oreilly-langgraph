{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define the search tool\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Simulated web search.\"\"\"\n",
    "    if \"sf\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "tools = [search]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Function to determine whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    return END if not state['messages'][-1].tool_calls else \"tools\"\n",
    "\n",
    "# source: https://langchain-ai.github.io/langgraph/#step-by-step-breakdown\n",
    "# Function to call the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state['messages'])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the workflow\n",
    "# we initialize graph (StateGraph) by passing state schema (in our case MessagesState)\n",
    "# MessagesState is a prebuilt state schema that has one attribute -- \n",
    "# a list of LangChain Message objects, as well as logic for merging the updates from each node into the state\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Initialize memory to persist state\n",
    "checkpointer = MemorySaver()\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Use the Runnable\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "print(final_state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
